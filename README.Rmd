---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# emlogit

<!-- badges: start -->
[![Build Status](https://travis-ci.com/soichiroy/emlogit.svg?branch=master)](https://travis-ci.com/soichiroy/emlogit)
<!-- badges: end -->

`emlogit` is a **R** package that implements the Expectation and Conditional-Maximization (ECM) algorithm for the multinomial logistic regression.


## Table of Contents

1. [Installation](#installation)
2. [Examples](#examples)

    a. [Categorical outcome](#categorical-outcome)
    b. [Multinomial outcome](#multinomial-outcome)
    c. [Binary/Binomial outcome (logistic regression)](#binary-outcome)

3. [References](#references)

## Installation

You can install the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("soichiroy/emlogit")
```

## Examples

### Categorical outcome

`Car` data from `mlogit` package.

```{r warning = FALSE, message = FALSE}
require(emlogit)
require(dplyr)
data(Car, package = 'mlogit')

## prepare data: only allow for indiviual specific covariates
y <- Car %>% select(choice)
Y <- model.matrix(~choice-1, data = y)
X <- Car %>% select(college, hsg2, coml5) %>% data.matrix()
```

```{r}
## fit
fit <- emlogit(Y = Y, X = X)
summary(fit)

## predicted probability
prob <- predict(fit)
```

```{r}
head(prob) %>%
  knitr::kable(digit = 3)
```

### Multinomial outcome

`japan` data from `MNP` package.

```{r}
## multinomial outcome
data(japan, package = "MNP")
head(japan)

Y <- japan %>% select(LDP, NFP, SKG, JCP) %>% data.matrix()
X <- japan %>% select(gender, education, age) %>% data.matrix()

set.seed(1234)
fit <- emlogit(Y = Y, X = X)
summary(fit)

pred <- predict(fit)
```

```{r}
head(pred) %>%
  knitr::kable(digit = 3)
```


### Binary outcome

Since the binomial outcome is a special case of multinomial outcomes,
`emlogit` can handle the binomial outcome.


```{r}
set.seed(1234)

## generate X and pi(X)
betas <- rnorm(4)
X     <- MASS::mvrnorm(5000, mu = rep(0, length(betas)), Sigma = diag(length(betas)))

prob  <- 1 / (1 + exp(- 0.5 - X %*% betas))

## generate outcome
ybin <- rbinom(n = 5000, size = 1, prob = prob)
Y    <- model.matrix(~ factor(ybin) - 1)

## fit
fit <- emlogit(Y = Y, X = X)


## check
betas <- c(0.5, betas)
cbind(true = betas, estimate = summary(fit)$estimate) %>%
  knitr::kable(digit = 3)
```


## References

The ECM algorithm used in this package utilizes the Polya-Gamma augmentation scheme originally developed by Polson et al. (2013).
Applications to the multinomial outcome in the context of deriving the EM algorithm based on Polya-Gamma representation can be found in Durante et al. (2019) and Goplerud (2019), among others.


+ Durante, D., Canale, A., & Rigon, T. (2019). [A nested expectation–maximization algorithm for latent class models with covariates.](https://doi.org/10.1016/j.spl.2018.10.015) _Statistics & Probability Letters,_ 146, 97-103.
+ Goplerud, M. (2019). [A Multinomial Framework for Ideal Point Estimation.](https://doi.org/10.1017/pan.2018.31) _Political Analysis,_ 27(1), 69-89.
+ Polson, N. G., Scott, J. G., & Windle, J. (2013). [Bayesian inference for logistic models using Pólya–Gamma latent variables.](https://doi.org/10.1080/01621459.2013.829001) _Journal of the American Statistical Association,_ 108(504), 1339-1349.
